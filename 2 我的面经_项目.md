# 我的面经 · 项目

本人面经之 **项目** 分栏，后续补充。

注意总结自己的心得体会。

https://time.geekbang.org/column/article/87636?code=FUJw-W0GO2XL%2F%2F4ypAWQkyPqACP3Y4MD5pc-ZFO7Oy0%3D



# DataFountain 疫情情绪识别

- **项目简介：**

  项目为 DataFountain 疫情期间的微博网民情绪识别，用官方给的数据集训练分析微博当时的舆论走向积极与否，参赛人数2503，参赛队伍 2049。

- **项目成绩：**

  经多日角逐，第一名 0.746；本队因条件（硬件）有限，最终得分 0.735，位 30-60 名。

- **项目过程：**

  开始单干，后面有几个朋友请求组队，同意组队后每日开会，商讨策略；

  换模型和使用五折交叉检验提升 0.04 左右，数据预处理删去重复ID提升 0.01 左右，调参提升 0.004 左右；

  看队伍提交，LSTM、textCNN；

  换模型 0.69、五折交叉、模型融合、对抗训练，效果不明显，最后目光放回数据，A榜 0.73530，B榜 0.73525，但排名反而提前。

## **初始版本**

- 导入相关的库

- 载入数据（多模态情感分析；标签分布不平衡，-1，1 较少；样本分布）
- 作图分析数据（看文本、图片、视频长度；多模态，但是只用文本，因为其他影响不大）
- 抛弃图片数据（url，60%有图片）
- 抛弃视频数据（url，25%有视频）
- 预训练（bert、embedding 填充长度统一；定义文本数据处理，编码从0开始，数据结果+1）
- 将数据变成 embedding、transformer => array
- 标签类别转换
- BERT 模型（三个输入，导入 bert，返回三个）
  - 最后一层 transformer 向量
  - pooling 将结果
  - 12 层 transformer 包
- 训练：五折交叉验证（稳定性提高；结果提高）
- 测试（有两种：平均概率相加；每折取出投票）
- 生成提交（结果 -1，返回 [-1, 0, 1]）

## **改良版本**

- 数据同上
- 采用
  - 修改模型
    - bert 修改，加入 LSTM、GRU 等作为 Encoder
    - bert 论文图，倒 4 层连起来（contact）效果最好
- 未采用（试过但效果一般）
  - 修改损失函数（Focal loss **平衡正负样本本身的比例不均**）
    - bert 输出 transformer 向量
    - 可接 LSTM encoding
  - 对抗训练

## **冠军方案**

- 优势：
  - 通用性 —> 扩展，不止疫情
  - 可落地 —> 前景好
  - 推    广 —> 合作
- 分析数据特点：
  - 口语化
  - 表情符 —> 乱码
  - 配图随意
  - 仅针对疫情
- 数据扩充和数据增广，回译方法无效（质量差）
- 多模态融合（图片数据无用，故此方法无效）
- focal loss —> 结果下降（故未采用）
- 后训练（post train，结合领域数据，微调 bert base）：
  - MLN（Masked Language Model，[MASK] 代替词，看预测是否正确）
  - NSP（Next Sentence Prediction，拼接看是否来自同一句）
- 对抗训练（adversarial training，NLP 中正则化提高泛化能力）
- F1 值适应优化（准确度最高的模型）以及多折模型融合（5-7 折效果好，再高不明显，得不偿失）
- 模型集成：词向量模型（bert 基于 wiki，对口语化微博一般）
  - 以下效果都不好
    - 1DCNN（1D，一维）
    - nCCNN（nC，多核）
    - douGRU（Double Gated Recurrent Unit，双向门控循环单元）
    - RNN（Recurrent Neural Network，循环神经网络）
    - Attention
    - RNN（Recursive Neural Network，递归神经网络）
  - 用 catboost 做 stacking
- 以上训练结果稳定性良好（离线 40 mins，实测 0.1 s，实用性强）

## **知识点**

- 项目说辞
  - 数据分析
  - 模型选择
  - 思考过程
  - 团队讨论
  - 最终结果
  - 改进方向

- 代码流程（PPT）
  - 预训练相关问题（bert的选取、知识蒸馏等）
  - 数据预处理（jieba、去重、embedding、token等）
  - Bert（concat、原理、论文）
  - 继承模型类
  - 调参
  - loss（为什么修改？）
  - 测试（平均 / 投票）
  - F1

- 使用库
  - pandas
  - numpy
  - sklearn（StratifiedKFold）
  - tqdm
  - tensorflow（tf、K、to_categorical）
  - transformers
  - jieba
- 方案尝试
  - 交叉验证
  - 模型融合
  - 对抗训练
  - LSTM
  - TextCNN
- 相关知识点：

  - Pytorch
  - Matplotlib
  - bert、transformers、attention 论文
  - 冠军方案


## **相关问题**

- 文本情感分类问题

  - 机器学习方法（TF-IDF、机器学习分类算法）
  - 深度学习方法（TextCNN、TextRNN 预训练模型）

- 预训练模型有哪些？（bert、albert、xnet、robert）

  - bert 相关问题：

    - bert input embedding = Token embedding（标注序列）+ Segment（段序列）+ Position（位置序列）

    - bert 论文

    - bert 源码

  - 对 transformers 的了解程度（transformers 有多个预训练模型，封装了 bert）

  - 对 bert 等预训练模型的理解

- 项目相关问题

  - 遇到了什么难点？怎么处理的？如何优化？
  - BERT 和 Word2Vec + TextRNN 比较？
  - BERT 在 pre train 时和 Word2vec 异同？损失函数？
  - BERT 中 Token 是分词的吗？
  - BERT 如何得到词意，句意？
  - BERT 为什么有 3 个嵌入层？如何实现？



# AI 昆虫识别

**项目简介：**昆虫识别，欸，就是玩儿~

## **亚军方案**

https://aistudio.baidu.com/aistudio/projectdetail/289616?channelType=0&channel=0

## 其他方案

https://aistudio.baidu.com/aistudio/projectdetail/266424?channelType=0&channel=0

ppyolo，paddlepaddle的yolo修改配置文件即可

## **知识点**

图像增广（MixUp（好比两个图透明重叠）、旋转等）

Yolo3（Detector，目标检测器）

ResNet50-vd-dcn（BackBone，骨干网络。残差神经网络，恒等模块神经网络越深效果反而不好，所以假设残差传递，结果真的更好。[vd 是什么？](https://github.com/PaddlePaddle/models/issues/2674)。[Deep & Cross Network(*DCN*)，深层交叉网络](https://zhuanlan.zhihu.com/p/43364598)）

[SENet](https://zhuanlan.zhihu.com/p/32702350) 分类网络（Squeeze-and-Excitation Networks，全局平均池化->（1*1\*C）全连接->sigmoid归一化，增强重要特征，削弱非重要特征，让提取的特征指向性更强。SENet 在卷积时会对每个特征图计算一个权重，以突出对结果增益高的特征图，从而进一步增强分类效果。）

IOU（真实框和检测框的重叠占比，即交/并）

mAP（mean Average Precision，各类别正确率的加权平均）

[NMS 和 Soft-NMS](https://blog.csdn.net/diligent_321/article/details/85859462)（NMS，哪个框分高就留下那个，重叠的多的就视为冗余；NMS 稠密对象可能会导致某些框不返回，所以引入 Soft-NMS，举例子，NMS把重叠太多的 0.8 框可能性给设为 0， SNMS 则可能为 0.4）

## **相关问题**





# 豆瓣 Top 500 电影

- **项目简介**：使用爬虫获取豆瓣网上 Top 500 的电影数据，并进行数据分析，如哪个电影类别最受欢迎、哪个年份

  爆款电影最多等。欸，就是玩儿


## **初始版本**

https://aistudio.baidu.com/aistudio/projectdetail/1240625

《深度学习导论与应用实践》

## **改良版本**

## **知识点**

**from** bs4 **import** BeautifulSoup 获取标签

xlrd、xlwt操作excel

## **相关问题**



# 机器阅读理解

- **项目简介**：类似百度时第一条的抽取回答 https://aistudio.baidu.com/aistudio/competition/detail/66


## **初始版本**

https://aistudio.baidu.com/aistudio/projectdetail/1564384



## **改良版本**

- **预训练模型**改良：https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/transformers.md

- **对抗训练**：通过在词向量中添加干扰词向量来生成干扰样本。重新训练模型，以增强模型的鲁棒性。

- **知识蒸馏，模型融合**等

## **知识点**

`SQuAD` 格式：https://www.cnblogs.com/xuehuiping/p/12262700.html

ERNIE

`start_loss`和`end_loss`和`cls_loss`，`mrc_loss = (start_loss + end_loss) / 2` => `loss = (mrc_loss + cls_loss) /2`

![image-20210517172947311](C:\Users\11046\AppData\Roaming\Typora\typora-user-images\image-20210517172947311.png)



## **相关问题**





# 多技能对话任务

- **项目简介**：本次用于评测的千言－多技能对话数据集涵盖了多个对话场景：包括画像对话、知识对话、推荐对话等。我们旨在衡量开放域对话模型在各个不同技能上的效果和模型通用性。 https://aistudio.baidu.com/aistudio/competition/detail/67


## **初始版本**

https://aistudio.baidu.com/aistudio/projectdetail/1640180



## **改良版本**

## **知识点**

![image-20210517134328536](C:\Users\11046\AppData\Roaming\Typora\typora-user-images\image-20210517134328536.png)

![image-20210517134401177](C:\Users\11046\AppData\Roaming\Typora\typora-user-images\image-20210517134401177.png)

用脚本将数据转化成id化

动态学习率

交叉熵

## **相关问题**





# 多形态信息抽取任务

- **项目简介**：让机器从自然语言文本中抽取实体、关系、事件等多形态知识，旨在使机器具备从海量非结构化文本信息中自动抽取结构化知识的能力。 https://aistudio.baidu.com/aistudio/competition/detail/65


## **初始版本**

- 关系抽取 Relation Extraction：https://aistudio.baidu.com/aistudio/projectdetail/1639963
- 事件抽取 Event Extraction：https://aistudio.baidu.com/aistudio/projectdetail/1639964



## **改良版本**

- 改用更大的预训练模型
- 模型集成
- GRU+CRF（事件抽取）

## **知识点**

数据集：百度自建的三个大规模中文信息抽取数据集——DuIE2.0、DuEE1.0和DuEE-fin

SPO：主体（subject），关系（predicate），客体（object），pipeline 管道抽取，先抽再识别哪个是SPO；end2end 联合抽取，输入、然后直接输出SPO三元组 https://blog.csdn.net/qq_35268841/article/details/107063066

BIO（ES）：Begin，In，Out，End，Single

优化器：Adam

损失函数：均方误差（关系抽取）；交叉熵（事件抽取）

评估：P/R/F1

## **相关问题**





# Baidu 舆论识别

- **项目简介：**

  项目为 DataFountain 疫情期间的微博网民情绪识别，用官方给的数据集训练分析微博当时的舆论走向积极与否，参赛人数2049，参赛队伍 2503。

- **项目成绩：**

  经多日角逐，第一名 0.746；本队因条件有限，最终得分 0.735，位 30-60 名。

- **项目过程：**

  开始单干，后面有几个朋友请求组队，同意组队后每日开会，商讨策略；


## **初始版本**



## **改良版本**



## **冠军方案**



## **知识点**



## **相关问题**

